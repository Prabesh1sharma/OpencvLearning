{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005ecc3a-4c36-4bbe-a546-493c62c0c46d",
   "metadata": {},
   "source": [
    "# Arithmetic Operations on Images Using Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd8bd61c-5585-4b42-bf97-a6fd2452ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a040cb-9a6e-4c98-98d7-5368971b91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Images/buttler.jpg')\n",
    "img2 = cv2.imread('Images/108899015_bf36131a57.jpg')\n",
    "\n",
    "img1= cv2.resize(img1,(500,700))\n",
    "img2= cv2.resize(img2,(500,700))\n",
    "\n",
    "new_img = cv2.addWeighted(img1,1,img2,0.3,2)\n",
    "cv2.imshow(\"OPencv\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02436d41-bb93-4de0-9e69-8f77aee98dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Images/buttler.jpg')\n",
    "img2 = cv2.imread('Images/108899015_bf36131a57.jpg')\n",
    "\n",
    "img1= cv2.resize(img1,(500,700))\n",
    "img2= cv2.resize(img2,(500,700))\n",
    "\n",
    "new_img = cv2.subtract(img1,img2)\n",
    "cv2.imshow(\"OPencv\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aecfa2-2b82-4402-a7f9-ece9efacb16b",
   "metadata": {},
   "source": [
    "### Bitwise Operation on Images using Opencv\n",
    "Bitwise operation on binary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79569efb-1f7f-4f88-b704-2eeb9f0c9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Images/images111.png')\n",
    "img2 = cv2.imread('Images/image12.png')\n",
    "\n",
    "img1=cv2.resize(img1, (500,500))\n",
    "img2=cv2.resize(img2, (500,500))\n",
    "\n",
    "new = cv2.bitwise_and(img1,img2)\n",
    "h = np.hstack((img1, img2, new))\n",
    "cv2.imshow('opencv',h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5643eb-88c5-4426-8fac-4439ea972932",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Images/images111.png')\n",
    "img2 = cv2.imread('Images/image12.png')\n",
    "\n",
    "img1=cv2.resize(img1, (500,500))\n",
    "img2=cv2.resize(img2, (500,500))\n",
    "\n",
    "new = cv2.bitwise_or(img1,img2)\n",
    "h = np.hstack((img1, img2, new))\n",
    "cv2.imshow('opencv',h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6545c953-d76c-46c4-8cd0-c0275277d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Images/images111.png')\n",
    "img2 = cv2.imread('Images/image12.png')\n",
    "\n",
    "img1=cv2.resize(img1, (500,500))\n",
    "img2=cv2.resize(img2, (500,500))\n",
    "\n",
    "new = cv2.bitwise_xor(img1,img2) #Not will be for only one image\n",
    "h = np.hstack((img1, img2, new))\n",
    "cv2.imshow('opencv',h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e98ce1-868a-4d63-9785-3ad2bb74bd81",
   "metadata": {},
   "source": [
    "# Edge detection using Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7668e3-171a-4651-ba9e-046e6e5696fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n",
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Images/buttler.jpg')\n",
    "img=cv2.resize(img, (500,500))\n",
    "print(img.shape)\n",
    "new_img = cv2.Canny(img, 100,100,apertureSize = 5,L2gradient=True) #200,200 is the threshold which defines the detailing to show\n",
    "#aperturesize and l2gradient also help to show the clear detailing of the image\n",
    "print(new_img.shape)\n",
    "cv2.imshow('opencv',new_img)\n",
    "cv2.imshow('opencv1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d9c8f-0565-45ac-a0a8-861856abe823",
   "metadata": {},
   "source": [
    "# Image Scaling, Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44bd987f-7655-406a-ac2f-959f6085f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/buttler.jpg')\n",
    "res_img = cv2.resize(img,(400,700))\n",
    "cv2.imshow('opencv1',img)\n",
    "cv2.imshow('opencv',res_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb13c99-a0b2-42cb-964b-ade04c084d5e",
   "metadata": {},
   "source": [
    "### Rotating the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f56ee8d-e0df-4179-a3fb-7336dfa2a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/buttler.jpg')\n",
    "# res_img = cv2.resize(img,(400,700))\n",
    "w,h = img.shape[0],img.shape[1]\n",
    "m = cv2.getRotationMatrix2D((w/2,h/2),180,0.5)\n",
    "new_img = cv2.warpAffine(res_img, m,(h,w) )\n",
    "h = np.hstack((img,new_img))\n",
    "cv2.imshow('opencv',h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635800b4-2942-45f3-9730-b244a3d0e4be",
   "metadata": {},
   "source": [
    "# Image Blurring using Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f62ece-bd99-4339-8e0d-a9f714094ade",
   "metadata": {},
   "source": [
    "`Type of Blurring`\n",
    "- Gaussian Blurring : \n",
    "- Median Blur\n",
    "- Bilateral Blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49f2f7-69f4-4e55-a9cb-0e87a9e0a692",
   "metadata": {},
   "source": [
    "# imwrite method using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d969d770-15f2-4354-858b-26e017ab8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = cv2.imread('Images/101654506_8eb26cfb60.jpg')\n",
    "org_img = cv2.resize(org_img,())\n",
    "g = cv2.GaussianBlur(org_img, (9,9),0)\n",
    "m = cv2.medianBlur(org_img,5)\n",
    "b = cv2.bilateralFilter(org_img,9,75,75)\n",
    "h = np.hstack((org_img,g))\n",
    "h1 = np.hstack((m,b))\n",
    "v = np.vstack((h,h1))\n",
    "cv2.imshow('opencv',v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36464193-b6b2-458b-bec1-4aaee9bafc0a",
   "metadata": {},
   "source": [
    "# Play the videos using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88347e50-e617-4da9-86b9-1041e0e4cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Images/448411157_26511716985085856_5565055629309195774_n.mp4')\n",
    "while cap.isOpened():\n",
    "    r,frame = cap.read() #r return boolen value if video is playing or not\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame,(600,400))\n",
    "        cv2.imshow(\"opencv\",frame)\n",
    "        # 0 in the waitkey show the first static frame\n",
    "        if cv2.waitKey(25) & 0xff == ord('p'): #press p to close the video\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8ce4a-eb6b-4c9b-a83a-775f3c2c77b7",
   "metadata": {},
   "source": [
    "# Capture video from camera using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b510f9ec-64a7-4673-8a6a-a1880a185ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap1 = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    r,frame = cap1.read()\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame,(500,500))\n",
    "        cv2.imshow(\"Opencv\",frame)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdefd13c-058c-42f7-83a1-0ff14fc1d08c",
   "metadata": {},
   "source": [
    "# Slow and Fast Motion video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3de667a0-0921-4da6-85ee-487479f6844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2 = cv2.VideoCapture('Images/448411157_26511716985085856_5565055629309195774_n.mp4')\n",
    "while cap2.isOpened():\n",
    "    r,frame = cap2.read() #r return boolen value if video is playing or not\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame,(600,400))\n",
    "        cv2.imshow(\"opencv\",frame)\n",
    "        #play fast and slow make changes on waitkey time which denotes frame per seconds\n",
    "        #low means high speed and vice versa\n",
    "        if cv2.waitKey(40) & 0xff == ord('p'): #press p to close the video\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9e0e9-f049-4691-bd8d-1fa837e6fb47",
   "metadata": {},
   "source": [
    "# Morphological Operation using Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf1bf3-cb05-4ca5-8e38-245c4331df81",
   "metadata": {},
   "source": [
    "- `Morphological operation are used to extract image components that are useful in the representaion and description of the region shape`\n",
    "- `it is typically performed on binary images`\n",
    "\n",
    "  ##### Morphological operation\n",
    "  - Erosion\n",
    "    It erodes away the boundaries of foreground object(Alwaus try to keep Foreground in white). The kernel slides through the image(as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero). Erosion removes white noises. Mainly use to srink \n",
    "  - Dilation\n",
    "    A pixel elemet is 1 if at least one pixel under the kernel is 1. So it increases the white region in the image or size of foreground object increases.Normally in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object\n",
    "  - Opening\n",
    "    OPening is just another name of erosion follwed by dilation. It is useful in removing noise.\n",
    "  - Closing\n",
    "    CLosing is reverse of opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object\n",
    "  - Morphological gradient\n",
    "    It is the difference between dilation and erosion of an image.\n",
    "  - Black hat\n",
    "    It is the difference between the closing of the input image and input image\n",
    "  - Top hat (also called \"White hat\")\n",
    "    It is the difference between input image and Opening of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbeef0ac-c461-4d63-ac0d-aa3b6d62f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/download.png\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "\n",
    "m = np.ones((10,10), np.int8)\n",
    "er = cv2.erode(img,m,iterations = 1)\n",
    "di = cv2.dilate(img,m,iterations = 1)\n",
    "h = np.hstack((img,er,di))\n",
    "cv2.imshow(\"opencv\",h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2dd4740-e3ff-4c28-b374-13b4b909fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening morphological\n",
    "img = cv2.imread(\"Images/download.png\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "k = np.ones((10,10), np.int8)\n",
    "op = cv2.morphologyEx(img,cv2.MORPH_OPEN,k,iterations=1) #it will removes the white nose\n",
    "cv2.imshow(\"opencv\",img)\n",
    "cv2.imshow(\"opencv1\",op)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7b12a11-d707-40da-964c-20186eaeb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/download.png\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "k = np.ones((10,10), np.int8)\n",
    "cl = cv2.morphologyEx(img,cv2.MORPH_CLOSE,k,iterations=1) #it will removes the black nose\n",
    "cv2.imshow(\"opencv\",img)\n",
    "cv2.imshow(\"opencv1\",cl)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2088714-055b-480f-bf2a-ec038fd367ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/download.png\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "k = np.ones((10,10), np.int8)\n",
    "gr = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,k,iterations=1) \n",
    "cv2.imshow(\"opencv\",img)\n",
    "cv2.imshow(\"opencv1\",gr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0819d027-da91-49f6-a332-410ac8fe45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/download.png\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "k = np.ones((20,20), np.int8)\n",
    "bt = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,k,iterations=1) \n",
    "cv2.imshow(\"opencv\",img)\n",
    "cv2.imshow(\"opencv1\",bt)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0bf9d1-cc6d-4c56-a87b-1f60112ddb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
