{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8a6413-4ac2-45ed-b05b-f413c10a7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94785d8-8462-4e16-a874-f52d7e574ac2",
   "metadata": {},
   "source": [
    "# Object Tracking and Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5b13d3-0fe5-4977-a174-838b24414cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Images/mixkit-man-and-woman-jogging-together-on-the-street-40881-hd-ready.mp4')\n",
    "\n",
    "n,f = cap.read()\n",
    "# Define the initial tracking window\n",
    "\n",
    "x,y,w,h = 290, 55, 230, 821 #roi\n",
    "t = (x,y,w,h)\n",
    "roi = f[y:y+h,x:x+w]\n",
    "\n",
    "# Set up the ROI for tracking\n",
    "\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi,np.array((0.,60.,32.)),np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria\n",
    "\n",
    "tr = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read() \n",
    "    if r == True:\n",
    "        # Convert the frame to HSV\n",
    "\n",
    "        hsv_f = cv2.cvtColor(f,cv2.COLOR_BGR2HSV)\n",
    "        #Backprojection\n",
    "        d = cv2.calcBackProject([hsv_f],[0],roi_hist,[0,180],1)\n",
    "        # Apply CamShift to get the new location\n",
    "\n",
    "        r,tp = cv2.CamShift(d,t,tr)\n",
    "\n",
    "        # Draw the tracking window on the frame\n",
    "        x,y,w,h = tp\n",
    "        final = cv2.rectangle(f,(x,y),(x+w,y+h),(0,0,255),4)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"opencv\",final)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xff == ord('p'): \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615efc3c-1d7e-4dc2-80b1-daa06e6c633a",
   "metadata": {},
   "source": [
    "# Corner Detection Using Detection Method (Harris Corner Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e771d1-1c39-41d3-8cd4-9bf5a9746e5f",
   "metadata": {},
   "source": [
    "\n",
    "- A corner can be interpreted as the junction of two edges(where an edge is a sudden changes in image brightness)\n",
    "- Harris Corner Detection algorithm wa developed to identify the internal corners of an image\n",
    "- The corners of an image are basically identified as the resgions where there area variation in large intensity of the gradient in all possible dimensions and directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c12c7be-8cfb-48f7-a53a-999f64cc5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"Images/shapessss.jpg\")\n",
    "\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gr = np.float32(gr)\n",
    "\n",
    "# Detect corners using the Harris Corner detection method\n",
    "res = cv2.cornerHarris(gr, 2, 3, 0.04)\n",
    "\n",
    "# Dilate corner image to enhance corner points\n",
    "res = cv2.dilate(res, None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "threshold = 0.01 * res.max()\n",
    "\n",
    "# Ensure the mask is the same shape as the image\n",
    "\n",
    "img[res > threshold] = [0, 0, 255]\n",
    "\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"opencv\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "534f6c38-b9fa-429f-8996-46ca9b7126c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"Images/buttler.jpg\")\n",
    "\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gr = np.float32(gr)\n",
    "\n",
    "# Detect corners using the Harris Corner detection method\n",
    "res = cv2.cornerHarris(gr, 2, 3, 0.04)\n",
    "\n",
    "# Dilate corner image to enhance corner points\n",
    "res = cv2.dilate(res, None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "threshold = 0.01 * res.max()\n",
    "\n",
    "# Ensure the mask is the same shape as the image\n",
    "\n",
    "img[res > threshold] = [0, 0, 255]\n",
    "\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"opencv\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd3e3a-d2c2-4edf-8d35-76791a8d6e96",
   "metadata": {},
   "source": [
    "# Corner Detection Using Detection Method (SHi-TOMASI CORNER DETECTION)\n",
    "- Shi-Tomasi corner detection was published by J.Shi and C.Tomasi in their paper \"Good Features to Track\"\n",
    "- Here the Basic Intuition is that corners can be detected by looking for significant changes in all direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2634e5bf-0fe5-4737-adc1-a0135d1ca115",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/shapessss.jpg\")\n",
    "# Convert the image to grayscale\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#corner point \n",
    "cr = cv2.goodFeaturesToTrack(gr,55,0.01,20) #55 is the number of corner point\n",
    "cr = np.int64(cr)\n",
    "\n",
    "for i in cr:\n",
    "    x,y = i.ravel() #simply convert into one linear\n",
    "    cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"opencv\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e873a90-10c0-4f33-8dab-c394f3245b36",
   "metadata": {},
   "source": [
    "# Object Detection using Haar-Cascade (Face Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c6f2b-db3c-4b36-ba90-1d3bb04111ef",
   "metadata": {},
   "source": [
    "- Haar-Cascade is an algorithm that can be detect objects in images, irrespective of their scale in image and location\n",
    "- This algorithm is not complex and can run in real-time. We can Train a Haar-Cascade detector to detect various objects like cars, bikes, building, fruits, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa61b9ed-c1a7-4d96-a3b0-16411d16559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/heros1.jpg\")\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "f = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\")\n",
    "d = f.detectMultiScale(gry,1.2,3)\n",
    "\n",
    "for (x,y,w,h) in d:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "cv2.imshow(\"OpenCV\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d845f-9fcd-4449-beb2-642c98eed38b",
   "metadata": {},
   "source": [
    "# Displaying Co-ordinates and Color code of the points clicked on the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42db4bd1-27c4-4459-b965-154b9bc7f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def click_b(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        s = f\"{x},{y}\"\n",
    "        cv2.putText(img, s, (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255))\n",
    "        cv2.imshow(\"Opencv\", img)\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        b = img[y,x,0]\n",
    "        g = img[y,x,1]\n",
    "        r = img[y,x,2]\n",
    "        s = f\"{b},{g},{r}\"\n",
    "        cv2.putText(img, s, (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255))\n",
    "        cv2.imshow(\"Opencv\", img)\n",
    "\n",
    "img = cv2.imread(\"Images/carbmw.jpg\")\n",
    "\n",
    "cv2.namedWindow(\"Opencv\")  # Create the window first\n",
    "cv2.setMouseCallback(\"Opencv\", click_b)\n",
    "\n",
    "cv2.imshow(\"Opencv\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea536e3-ef96-4f1c-88af-87a1f7714a64",
   "metadata": {},
   "source": [
    "# Play video in a reverse Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5954768-1f85-485b-8114-a66b84b66d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cap = cv2.VideoCapture('Images/mixkit-man-and-woman-jogging-together-on-the-street-40881-hd-ready.mp4')\n",
    "l=[]\n",
    "c = 1\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read() \n",
    "    \n",
    "    if r == True:\n",
    "        file_name = \"new_folder/demo\"+str(c)+\".jpg\"\n",
    "        l.append(file_name)\n",
    "        cv2.imwrite(file_name,f)\n",
    "        c=c+1\n",
    "        cv2.imshow(\"opencv\",f)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xff == ord('p'): \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "l.reverse()\n",
    "for i in l:\n",
    "    img_new = cv2.imread(i)\n",
    "    \n",
    "    cv2.imshow(\"hancy\",img_new)\n",
    "    if cv2.waitKey(25) & 0xff == ord('p'): \n",
    "            break\n",
    "    os.remove(i)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5697684-5b44-45da-b6d6-c0ec8f032c71",
   "metadata": {},
   "source": [
    "# Vechile Detection in a video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090ae13d-fc12-4511-a907-881d7e228d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Images/car.mp4')\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read() \n",
    "    \n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(600,400))\n",
    "        gry = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        car = cv2.CascadeClassifier('Images/cars.xml')\n",
    "        cars = car.detectMultiScale(gry,1.4,2)\n",
    "        for (x,y,w,h) in cars:\n",
    "            cv2.rectangle(f,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        cv2.imshow(\"opencv\",f)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xff == ord('p'): \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1312b-33df-4663-839c-ec27a4b498a3",
   "metadata": {},
   "source": [
    "# Simle and Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d88a3e99-13f4-4cd7-b431-af0f5c96fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#smile\n",
    "img = cv2.imread(\"Images/Screenshot 2024-06-22 124650.png\")\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "sm = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_smile.xml\")\n",
    "fc = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "f = fc.detectMultiScale(gry,1.3,3)\n",
    "for (x,y,w,h) in f:\n",
    "    roi_gry = gry[y:y+h,x:x+w]\n",
    "    roi_img = img[y:y+h,x:x+w]\n",
    "\n",
    "    s = sm.detectMultiScale(roi_img,1.9,4)\n",
    "    for (xs,ys,ws,hs) in s:\n",
    "        cv2.rectangle(roi_img,(xs,ys),(xs+ws,ys+hs),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# cv2.imshow(\"Opencv1\",roi_img)    \n",
    "cv2.imshow(\"Opencv\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cc2c294-09ef-48e9-a94e-f6cadcc20f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eye\n",
    "img = cv2.imread(\"Images/Screenshot 2024-06-22 124650.png\")\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "sm = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_eye.xml\")\n",
    "fc = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "f = fc.detectMultiScale(gry,1.3,3)\n",
    "for (x,y,w,h) in f:\n",
    "    roi_gry = gry[y:y+h,x:x+w]\n",
    "    roi_img = img[y:y+h,x:x+w]\n",
    "\n",
    "    s = sm.detectMultiScale(roi_img,1.9,7)\n",
    "    for (xs,ys,ws,hs) in s:\n",
    "        cv2.rectangle(roi_img,(xs,ys),(xs+ws,ys+hs),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# cv2.imshow(\"Opencv1\",roi_img)    \n",
    "cv2.imshow(\"Opencv\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77521d-75cb-42f7-b81c-445162736fb9",
   "metadata": {},
   "source": [
    "# Pedestrian Detection from a streaming video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a208318f-c9f4-4953-85a0-88d39995e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Images/mixkit-man-and-woman-jogging-together-on-the-street-40881-hd-ready.mp4')\n",
    "l=[]\n",
    "c = 1\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read() \n",
    "    \n",
    "    if r == True:\n",
    "        gry = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        hm = cv2.CascadeClassifier(r\"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_fullbody.xml\")\n",
    "        h = hm.detectMultiScale(gry,1.1,4)\n",
    "\n",
    "        for (x,y,w,h) in h:\n",
    "            cv2.rectangle(f,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "        cv2.imshow(\"opencv\",f)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xff == ord('p'): \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc035a-9ede-4273-b87d-743585ee4e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
